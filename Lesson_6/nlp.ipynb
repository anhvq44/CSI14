{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32722cd6",
   "metadata": {},
   "source": [
    "> NLP: NATURAL LANGUAGE PROGRESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9252f540",
   "metadata": {},
   "source": [
    "# Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9af59dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82aa14e9",
   "metadata": {},
   "source": [
    "# Add data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3df1af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tôi thích học khoá Computer Science.', 'Bạn có đam mê khoa học máy tính không?', 'Huy thích lập trình giải quyết vấn đề.', 'An muốn lập trình game bằng Python.', 'Mỹ có nhiều dự án Scratch hay.', 'Em thấy lập trình giống với trò chơi giải đố.', 'Không có gì đã bằng code chạy lần đầu tiên đúng luôn', 'Sở thích của mình là lập trình các dự án hay']\n"
     ]
    }
   ],
   "source": [
    "# Dữ liệu mẫu\n",
    "sentences = [\n",
    "    \"Tôi thích học khoá Computer Science.\",\n",
    "    \"Bạn có đam mê khoa học máy tính không?\",\n",
    "    \"Huy thích lập trình giải quyết vấn đề.\",\n",
    "    \"An muốn lập trình game bằng Python.\",\n",
    "    \"Mỹ có nhiều dự án Scratch hay.\",\n",
    "    \"Em thấy lập trình giống với trò chơi giải đố.\",\n",
    "    \"Không có gì đã bằng code chạy lần đầu tiên đúng luôn\",\n",
    "    \"Sở thích của mình là lập trình các dự án hay\"\n",
    "]\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6593ad",
   "metadata": {},
   "source": [
    "# Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef93f5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=100, oov_token=\"<OOV>\") #giới hạn cho 100 tử phổ biến nhất, sd OOV cho từ ngoài từ vựng"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4f9b1e",
   "metadata": {},
   "source": [
    "# Train - Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5914145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<OOV>': 1,\n",
      " 'an': 27,\n",
      " 'bạn': 17,\n",
      " 'bằng': 9,\n",
      " 'chơi': 39,\n",
      " 'chạy': 44,\n",
      " 'code': 43,\n",
      " 'computer': 15,\n",
      " 'các': 54,\n",
      " 'có': 5,\n",
      " 'của': 51,\n",
      " 'dự': 10,\n",
      " 'em': 34,\n",
      " 'game': 29,\n",
      " 'giải': 8,\n",
      " 'giống': 36,\n",
      " 'gì': 41,\n",
      " 'hay': 12,\n",
      " 'huy': 23,\n",
      " 'học': 6,\n",
      " 'khoa': 20,\n",
      " 'khoá': 14,\n",
      " 'không': 7,\n",
      " 'luôn': 49,\n",
      " 'là': 53,\n",
      " 'lần': 45,\n",
      " 'lập': 2,\n",
      " 'muốn': 28,\n",
      " 'máy': 21,\n",
      " 'mê': 19,\n",
      " 'mình': 52,\n",
      " 'mỹ': 31,\n",
      " 'nhiều': 32,\n",
      " 'python': 30,\n",
      " 'quyết': 24,\n",
      " 'science': 16,\n",
      " 'scratch': 33,\n",
      " 'sở': 50,\n",
      " 'thích': 4,\n",
      " 'thấy': 35,\n",
      " 'tiên': 47,\n",
      " 'trình': 3,\n",
      " 'trò': 38,\n",
      " 'tính': 22,\n",
      " 'tôi': 13,\n",
      " 'vấn': 25,\n",
      " 'với': 37,\n",
      " 'án': 11,\n",
      " 'đam': 18,\n",
      " 'đã': 42,\n",
      " 'đúng': 48,\n",
      " 'đầu': 46,\n",
      " 'đề': 26,\n",
      " 'đố': 40}\n"
     ]
    }
   ],
   "source": [
    "tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "pprint(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9255419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Câu gốc: Tôi thích học khoá Computer Science.\n",
      "Tokenized: [13, 4, 6, 14, 15, 16]\n",
      "\n",
      "Câu gốc: Bạn có đam mê khoa học máy tính không?\n",
      "Tokenized: [17, 5, 18, 19, 20, 6, 21, 22, 7]\n",
      "\n",
      "Câu gốc: Huy thích lập trình giải quyết vấn đề.\n",
      "Tokenized: [23, 4, 2, 3, 8, 24, 25, 26]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#dùng tokenizer để huấn luyện tokenizer 3 câu đầu\n",
    "test_tokenizer = sentences[0:3]\n",
    "sequences = tokenizer.texts_to_sequences(test_tokenizer)\n",
    "\n",
    "for i, seq in enumerate(sequences):\n",
    "    print(f\"Câu gốc: {test_tokenizer[i]}\")\n",
    "    print(f\"Tokenized: {seq}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2820c1",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c1bfab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = [\n",
    "    \"Tôi yêu lập trình\",\n",
    "    \"Học khoa học máy tính thật thú vị\",\n",
    "    \"Python là ngôn ngữ tuyệt vời để bắt đầu.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4e73317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Câu gốc: Tôi yêu lập trình\n",
      "Tokenized: [13, 1, 2, 3]\n",
      "\n",
      "Câu gốc: Học khoa học máy tính thật thú vị\n",
      "Tokenized: [6, 20, 6, 21, 22, 1, 1, 1]\n",
      "\n",
      "Câu gốc: Python là ngôn ngữ tuyệt vời để bắt đầu.\n",
      "Tokenized: [30, 53, 1, 1, 1, 1, 1, 1, 46]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_sequences = tokenizer.texts_to_sequences(test_data)\n",
    "\n",
    "for i, seq in enumerate(test_sequences):\n",
    "    print(f\"Câu gốc: {test_data[i]}\")\n",
    "    print(f\"Tokenized: {seq}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7e2fcc",
   "metadata": {},
   "source": [
    "# Pad sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad6278c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  1  2  3  0  0  0  0  0  0]\n",
      " [ 6 20  6 21 22  1  1  1  0  0]\n",
      " [30 53  1  1  1  1  1  1 46  0]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import pad_sequences\n",
    "\n",
    "padded_sequences = pad_sequences(test_sequences, maxlen=10, truncating=\"post\", padding=\"post\")\n",
    "print(padded_sequences)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
